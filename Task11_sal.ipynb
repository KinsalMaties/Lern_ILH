{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPg0iQMXaN7wIuRp9JuDxhM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KinsalMaties/Lern_ILH/blob/main/Task11_sal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iU5RViZyBXfS"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import FreqDist\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import urllib.request\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка данных\n",
        "DATA_URL = \"https://www.gutenberg.org/files/2142/2142-h/2142-h.htm\"\n",
        "opener = urllib.request.URLopener({})\n",
        "resource = opener.open(DATA_URL)\n",
        "charset = resource.headers.get_content_charset()\n",
        "raw_text = resource.read().decode(charset if charset else \"utf-8\")"
      ],
      "metadata": {
        "id": "p1Lk7u_CBbqn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Предварительная обработка текста\n",
        "clean_pattern = re.compile(\"End of the Project Gutenberg EBook.*\")\n",
        "cleaner_text = re.sub(clean_pattern, \"\", raw_text.replace(\"\\n\", \" \").replace(\"\\r\", \" \"))\n"
      ],
      "metadata": {
        "id": "4GUqrDkaBf7G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOMtPJJxB7iX",
        "outputId": "db70a85d-55e3-4726-b529-39c09eb7e349"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Токенизация текста\n",
        "tokens = word_tokenize(cleaner_text)"
      ],
      "metadata": {
        "id": "yRi_2XnXBj8G"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Задача 1: Подсчет общего количества токенов букв\n",
        "num_letter_tokens = sum(1 for token in tokens if token.isalpha())\n",
        "print(\"1. Number of letter tokens:\", num_letter_tokens)\n",
        "\n",
        "# Подсчет частоты встречаемости токенов\n",
        "fdist = FreqDist(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEpjY46lBme2",
        "outputId": "412511ef-e6cb-46b8-ea72-773088b6943e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Number of letter tokens: 41193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_lgC0dECMRu",
        "outputId": "daea38b7-24dc-4524-ab19-0a0d8cee02cf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Задача 2: Определение доли стоп-слов среди 100 наиболее часто встречающихся токенов\n",
        "# Выбираем 100 наиболее часто встречающихся токенов\n",
        "top_100_tokens = [token for token, freq in fdist.most_common(100)]\n",
        "# Определение стоп-слов\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "# Подсчет стоп-слов среди 100 наиболее часто встречающихся токенов\n",
        "num_stopwords_in_top_100 = sum(1 for token in top_100_tokens if token.lower() in stop_words)\n",
        "# Доля стоп-слов среди 100 наиболее часто встречающихся токенов\n",
        "share_of_stopwords = num_stopwords_in_top_100 / 100\n",
        "print(\"2. Share of stop-words of 100 most frequent tokens in the text:\", round(share_of_stopwords, 2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e767letyBt0O",
        "outputId": "97c14c66-3055-4cca-fe8f-496a2f2afbf7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2. Share of stop-words of 100 most frequent tokens in the text: 0.61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Задача 3: Подсчет количества токенов, встречающихся более 50 раз\n",
        "# Подсчет количества токенов, встречающихся более 50 раз\n",
        "num_tokens_greater_than_50 = sum(1 for freq in fdist.values() if freq > 50)\n",
        "print(\"3. Amount of tokens encountered in the text strictly greater than 50 times:\", num_tokens_greater_than_50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tWsO5ozCGVu",
        "outputId": "4deb25f5-c903-4be4-8da6-8165c98d4cb2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3. Amount of tokens encountered in the text strictly greater than 50 times: 130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5vhWR4KMCVVO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}